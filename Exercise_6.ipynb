{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A3LeQEbnlSd2"
   },
   "source": [
    "# Introduction to classes (object oriented programming)\n",
    "\n",
    "Classes provide a means of bundling data and functionality together. Creating a new class creates a new type of object, allowing new instances of that type to be made. Each class instance can have attributes attached to it for maintaining its state. Class instances can also have methods (defined by its class) for modifying its state.\n",
    "\n",
    "The **self** parameter is a reference to the current instance of the class, and is used to access variables that belongs to the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pEbWIcR9lSd9"
   },
   "outputs": [],
   "source": [
    "# definte the class for a person\n",
    "class Person:\n",
    "    '''\n",
    "    This class represent a Person.\n",
    "    : attribute first_name: First name of the person\n",
    "    : attribute last_name: Last name of the person    \n",
    "    '''\n",
    "    # __ indicates internal functions, __method__ indicates special python method\n",
    "    def __init__(self, first_name=None, last_name=None):\n",
    "        '''\n",
    "        This function is always called when an instance of a class is created(Constructor).\n",
    "        The __init__() function is used to assign values to object properties or\n",
    "        other operations that are necessary to do when the object is being created.\n",
    "        \"self\" always needs to be set as the first argument in order for the methods to be able to access class attributes (like first and lasts name)\n",
    "        In this example first and last name are given to the constructor to create an instance.\n",
    "        '''\n",
    "        # within classes attributes are defined with the pattern self.attribute.\n",
    "        # this way attributes cann be accessed within the class definition by self.attribute or in the instance of a class (object) like object.attribute\n",
    "        self.first_name = first_name\n",
    "        self.last_name = last_name    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3d09c4bxMENT"
   },
   "outputs": [],
   "source": [
    "# define a class patient that inherits all the attributes from person\n",
    "class Patient(Person):\n",
    "    '''\n",
    "    This class is inherited from Person class. It represents Patients.\n",
    "    : attribute patient_id: ID number of patient\n",
    "    '''\n",
    "    def __init__(self, first_name=None, last_name=None, pid=None):\n",
    "        '''\n",
    "        Constructor of Patient class.\n",
    "        We also call the constructor of the class Person from which it was inherited from.\n",
    "        '''\n",
    "        super(Patient, self).__init__(first_name, last_name)\n",
    "        self.patient_id = pid\n",
    "      \n",
    "    def __str__(self):\n",
    "        '''\n",
    "        This function is called when we want to print the details of an object of the class\n",
    "        '''\n",
    "        return (\"Name: {} {} \\n Patient ID: {} \\n\".format(self.first_name, self.last_name, self.patient_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Rh7bX3qMG6g"
   },
   "outputs": [],
   "source": [
    "# now lets define a class waiting room that has a list of patients similar to a dataset\n",
    "class WaitingRoom:\n",
    "    '''\n",
    "    This class represent a waiting room. We have list of patients waiting.\n",
    "    : attribute patient: a list of patients\n",
    "    '''\n",
    "    def __init__(self, patients=None):\n",
    "        '''\n",
    "        Constructor, expects a list of instances of class patient\n",
    "        '''\n",
    "        self.patients = patients\n",
    "    \n",
    "    def __getitem__(self, index=None):\n",
    "        '''\n",
    "        This function return a patient using the index. We can then iterate over the class instance  like a list.\n",
    "        '''\n",
    "        return self.patients[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        '''\n",
    "        Returns the number of patients in the room\n",
    "        '''\n",
    "        return len(self.patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ipIwEO8flSeF"
   },
   "outputs": [],
   "source": [
    "# We declare two patients\n",
    "patient_1 = Patient(\"Wayne\", \"Rooney\", \"1234\")\n",
    "patient_2 = Patient(\"Wayne\", \"Bridge\", \"1214\")\n",
    "\n",
    "# Declare a list of patients and add the patients to this list\n",
    "patients = []\n",
    "patients.append(patient_1)\n",
    "patients.append(patient_2)\n",
    "\n",
    "# Add the patients to the waiting room\n",
    "\n",
    "waiting_room = WaitingRoom(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RMPKUafVlSeL"
   },
   "outputs": [],
   "source": [
    "# Let see how many people are there in the waiting room\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fL9328iqN_8P"
   },
   "outputs": [],
   "source": [
    "# access the first name of the first patient in the waiting room\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xW2wcJHdlSeQ"
   },
   "outputs": [],
   "source": [
    "# Let is loop over the patients in the waiting room and print their details\n",
    "\n",
    "for p in waiting_room:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c7j5FQ4IlSeV"
   },
   "source": [
    "# Get the data (Recap)\n",
    "\n",
    "First we need access to data. \n",
    "- You can use this link to add the data to your drive: https://drive.google.com/drive/folders/1pHNxZVrlcKh5usWoNC_V7gR2WdeDutjv\n",
    "\n",
    "- Then go inside the folder **CS_for_MedStudents_data** and you will see the folder **HAM10000**.\n",
    "- Right click on the **HAM10000** folder and click on the **Add to my Drive** option.\n",
    "\n",
    "Now you can run the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lp5-xntxlSeW"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eFZmhYBylSeZ"
   },
   "outputs": [],
   "source": [
    "data_dir = \"/content/drive/My Drive/CS_for_MedStudents_Data/HAM10000\"\n",
    "classes = [ 'actinic keratoses', 'basal cell carcinoma', 'benign keratosis-like lesions', \n",
    "           'dermatofibroma','melanoma', 'melanocytic nevi', 'vascular lesions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NCSW-Zi5RIh1"
   },
   "outputs": [],
   "source": [
    "# quick example for object oriented programming: working with paths (folders and files)\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7yGw5zTeRMZC"
   },
   "outputs": [],
   "source": [
    "dataset_folder = Path(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kAXs1ZD8SVAY"
   },
   "outputs": [],
   "source": [
    "# get the name of folder / file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IonIhX21Sfde"
   },
   "outputs": [],
   "source": [
    "# get the path objective of the parent folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x1q8DO50S2XO"
   },
   "outputs": [],
   "source": [
    "# does the folder nv exist in our path?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0WzvASh3RRlQ"
   },
   "outputs": [],
   "source": [
    "for path in dataset_folder.glob('*'):\n",
    "  print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rfvxo1CNlSec"
   },
   "source": [
    "# Data Augmentation\n",
    "\n",
    "It is a common fact that medical data is scarce. But to learn a very good model, the network needs a lot of data. So to tackle the problem we perform data augmentation.\n",
    "\n",
    "Data augmentation is a strategy that enables practitioners to significantly increase the diversity of data available for training models, without actually collecting new data. \n",
    "\n",
    "Data augmentation techniques such as cropping, padding, and horizontal flipping are commonly used to train large neural networks.\n",
    "\n",
    "![Data Augmentation](https://cdn-images-1.medium.com/max/1000/1*C8hNiOqur4OJyEZmC7OnzQ.png)\n",
    "[Source](https://cdn-images-1.medium.com/max/1000/1*C8hNiOqur4OJyEZmC7OnzQ.png) \n",
    "\n",
    "\n",
    "**Normalization**\n",
    "Data normalization is an important step which ensures that each input parameter (pixel, in this case) has a similar data distribution. This makes convergence faster while training the network. \n",
    "\n",
    "Data normalization is done by subtracting the mean from each pixel and then dividing the result by the standard deviation. The distribution of such data would resemble a Gaussian curve centered at zero. \n",
    "\n",
    "![Normalization](http://agnesmustar.com/wp-content/uploads/2017/09/image_normalization-1024x353.jpeg)\n",
    "[Source](http://agnesmustar.com/wp-content/uploads/2017/09/image_normalization-1024x353.jpeg) \n",
    "\n",
    "Since, skin lesion images are natural images, we use the normalization values (mean and standard deviation) from [Imagenet dataset.](http://www.image-net.org/)\n",
    "*norm_mean = (0.4914, 0.4822, 0.4465)*\n",
    "\n",
    "*norm_std = (0.2023, 0.1994, 0.2010)*\n",
    "\n",
    "This denotes mean and standard deviation for each channel(RGB) of an image.\n",
    "\n",
    "\n",
    "We perform following data augmentation:\n",
    "- Resize the image.\n",
    "- Flipping the image horizontally.\n",
    "- Randomly rotating image.\n",
    "- Normalizing the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ces4rS8jlSed"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Imagenet values\n",
    "norm_mean = (0.4914, 0.4822, 0.4465)\n",
    "norm_std = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "# define the transformaitons the images go through each time it is used for training\n",
    "# includes augmentation AND normalization as descirbed above\n",
    "augmentation_train = transforms.Compose([\n",
    "                                  # resize image to the network input size\n",
    "                                  transforms.Resize((224,224)),\n",
    "                                  # randomly perform a horizontal flip of the image\n",
    "                                  transforms.RandomHorizontalFlip(),\n",
    "                                  # rotate the image with a angle from 0 to 60 (chosen randomly)\n",
    "                                  transforms.RandomRotation(degrees=60),\n",
    "                                  # convert the image into a tensor so it can be processed by the GPU\n",
    "                                  transforms.ToTensor(),\n",
    "                                  # normalize the image with the mean and std of ImageNet\n",
    "                                  transforms.Normalize(norm_mean, norm_std),\n",
    "                                   ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OmKhIV4VlSeh"
   },
   "source": [
    "**Note**: An important aspect is that we only augment the images used for training. So for testing we don't use the geometric augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WXV6_dOalSei"
   },
   "outputs": [],
   "source": [
    "# no augmentation for the test data only resizing, conversion to tensor and normalization\n",
    "augmentation_test = transforms.Compose([\n",
    "                    transforms.Resize((224,224)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "                    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yNLSsXlYlSem"
   },
   "source": [
    "# Loading the data\n",
    "\n",
    "Use the **torchvision.datasets.ImageFolder** dataset class. This class requires the dataset to be arranged into folders of their respective class or labels. We already provide the dataset in suitable preprocessed format.\n",
    "\n",
    "Here we also apply the augmentation that we defined above.\n",
    "\n",
    "You can check here : https://pytorch.org/docs/stable/torchvision/datasets.html#imagefolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "61k4h0yXlSen"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "# create an instance of the image folder class to load images by classes defined with the folders given\n",
    "dataset = torchvision.datasets.ImageFolder(root= data_dir, transform= augmentation_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kop4udupouUg"
   },
   "source": [
    "Let's try to use the __getitem__ method of the ImageFolder class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6i1HoAColSeq"
   },
   "outputs": [],
   "source": [
    "# Check the dimension of the 1000th image and its corresponding label\n",
    "\n",
    "image, label = dataset[1000]\n",
    "print(\"Image Shape: {} \\n Label: {} \\n Lesion Type: {}\".format(image.shape, label, classes[label]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uwzF3-r9lSet"
   },
   "source": [
    "# Train, Test and Validation Split\n",
    "It is a best practice to split the entire dataset into 3 parts:\n",
    "- Train: Used to train a network.\n",
    "- Validation: Fine tune the network.\n",
    "- Test: Kept as unseen data to gauge the performance of out trained network.\n",
    "\n",
    "\n",
    "The splitting should be done class wise so that we have equal representation of all classes in each subset of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2s6SFpQClSeu"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# get the total amount of images in the dataset\n",
    "num_train = len(dataset)\n",
    "\n",
    "# create a list of indices for the whole dataset\n",
    "indices = list(range(num_train))\n",
    "\n",
    "# get the class labels from the dataset object (0-6)\n",
    "class_labels = dataset.targets\n",
    "\n",
    "# define the percentage of data that is not used for training\n",
    "split_size = 0.2\n",
    "\n",
    "# call a function of sklarn that takes care of splitting the dataset into training and validation+testing\n",
    "train_indices, test_indices, class_labels_train, class_labels_test = train_test_split(indices,\n",
    "                                                                                       class_labels,\n",
    "                                                                                       test_size=split_size,\n",
    "                                                                                       shuffle=True,\n",
    "                                                                                       stratify= class_labels,\n",
    "                                                                                       random_state=42)\n",
    "\n",
    "# call a function of sklearn that splits validation+testing into validation and testing\n",
    "train_indices, val_indices = train_test_split(train_indices,\n",
    "                                               test_size=split_size,\n",
    "                                               shuffle=True,\n",
    "                                               stratify= class_labels_train,\n",
    "                                               random_state=42)\n",
    "\n",
    "# Creating data samplers and loaders using the indices:\n",
    "SubsetRandomSampler = torch.utils.data.sampler.SubsetRandomSampler\n",
    "\n",
    "# create instances of a torch class for picking random samples from our dataset\n",
    "train_samples = SubsetRandomSampler(train_indices)\n",
    "val_samples = SubsetRandomSampler(val_indices)\n",
    "test_samples = SubsetRandomSampler(test_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_BUDZRBzlSe0"
   },
   "source": [
    "# Dataloader\n",
    "\n",
    "We will now use the dataloader to load the entire dataset in small batches.\n",
    "\n",
    "**Epochs vs Iteration vs Batch size**\n",
    "\n",
    "One **Epoch** is when an ENTIRE dataset is passed forward and backward through the neural network only ONCE.\n",
    "Now, we have more than 10000 images in our dataset. It is not possible to feed the entire dataset at once to the computer. So, we divide the data into several smaller batches.\n",
    "\n",
    "**Batch Size** is number of training examples present in a single batch.\n",
    "\n",
    "**Iterations** are the number of batches needed to complete one epoch.\n",
    "\n",
    "An Example:\n",
    "\n",
    "If we have 10000 training images in our dataset. We can divide the dataset into **batches of 500** then it will take **4 iterations** to complete **1 epoch**.\n",
    "\n",
    "\n",
    "That's where a pytorch dataloader is useful: https://pytorch.org/docs/stable/data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vZv7MX3PlSe1"
   },
   "outputs": [],
   "source": [
    "# define the batch size for training, val and testing\n",
    "batch_size, validation_batch_size, test_batch_size = 32, 32, 32\n",
    "\n",
    "# create and instance of a dataloader for training\n",
    "train_data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False,num_workers=1, sampler= train_samples)\n",
    "\n",
    "# overwrite the dataset instance with the test augmentation (this is not nice code)\n",
    "dataset = torchvision.datasets.ImageFolder(root= data_dir, transform=augmentation_test)\n",
    "# create instances of a dataloaders for validation and testing\n",
    "validation_data_loader = torch.utils.data.DataLoader(dataset, batch_size=validation_batch_size, shuffle=False, sampler=val_samples)\n",
    "test_data_loader = torch.utils.data.DataLoader(dataset, batch_size=test_batch_size, shuffle=False, sampler=test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g5_oUPN9Z9PH"
   },
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mac_drJ5nUjP"
   },
   "source": [
    "Let us display the loaded batched images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uwJzcQXXm_gz"
   },
   "outputs": [],
   "source": [
    "# import libraries for simple image plotting and \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "fig = plt.figure(figsize=(30, 30))\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # denormalize change this\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get first batch of training images\n",
    "dataiter = iter(train_data_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s, ' % classes[labels[j]] for j in range(len(labels))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ei4V3lwyquFz"
   },
   "source": [
    "Now, we have our dataset loaded Let's try to do something cool with it.\n",
    "\n",
    "For now, we will use an pre trained network to do inference on the test set of out data. Let's see how is the performance without training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YBj-R8SprHm-"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# load a pretrained model\n",
    "from torch import nn\n",
    "import torchvision\n",
    "\n",
    "num_classes = len(classes)\n",
    "net = torchvision.models.resnet18(pretrained = True)\n",
    "\n",
    "# We replace last layer of resnet to match our number of classes which is 7\n",
    "# more details next lecture\n",
    "net.fc = nn.Linear(512, num_classes)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CRKNvPsFrCQ4"
   },
   "outputs": [],
   "source": [
    "# counter for correct predictions\n",
    "correct = 0\n",
    "# counter for all predicted samples\n",
    "total = 0\n",
    "\n",
    "# set network to evaluation mode (next lecture)\n",
    "net.eval()\n",
    "\n",
    "# this is for next lecture..\n",
    "with torch.no_grad():\n",
    "  dataiter = iter(train_data_loader)\n",
    "  images, labels = dataiter.next()\n",
    "  images, labels = images.to(device), labels.to(device)\n",
    "  outputs = net(images)\n",
    "  _, predicted = torch.max(outputs.data, 1)\n",
    "  total += labels.size(0)\n",
    "  correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yRQvMJssioq0"
   },
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A3sD9kHCxMFr"
   },
   "outputs": [],
   "source": [
    "# add the following functions to the waiting room class above (you need to redefine the whole class again)\n",
    "\n",
    "def enter_room(self, patient=None):\n",
    "\"\"\" adds a patient object to the list of patients \"\"\"\n",
    "\n",
    "def leave_room(self, index=None)\n",
    "\"\"\" removes a patient from the list of patients\n",
    "hint: use list.pop([i]) https://docs.python.org/2/tutorial/datastructures.html "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise_6.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
