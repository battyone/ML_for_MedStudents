{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging your code\n",
    "\n",
    "It is very rare for a code to work perfectly for the first time. There usually many erros which maybe syntactical mistakes or flaws in the logic of the code itself. That is why it is absolutely essential to be able to debug your code. Debugging has two steps:\n",
    "- Understand the error message.\n",
    "- Find the source of the error.\n",
    "- Find a solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case sensitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name = \"Max\"\n",
    "Age = \"20\"\n",
    "\n",
    "print(\"My name is {} and I am {} years old\".format(name,age))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reserved keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Max\"\n",
    "class = 5\n",
    "\n",
    "print(\"My name is {} and study in class {}.\".format(name,class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating over lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = ['cat', 'dog', 'mouse']\n",
    "\n",
    "for i in range(spam):\n",
    "\n",
    "    print(spam[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to concatenate a non-string value to a string value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numEggs = 12\n",
    "\n",
    "print('I have ' + numEggs + ' eggs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = ['cat', 'dog', 'mouse']\n",
    "\n",
    "print(spam[3])\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find factors of 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    if 10%i == 0:\n",
    "        print(\"{}\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have defined some four functions here. These four functions are being called by a parent function.\n",
    "Try to run these cells and solve the errors you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to count the sum of first N natural numbers\n",
    "\n",
    "def count(n)\n",
    "    count = n(n+1)/2\n",
    "return count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to count the sum of even natural numbers till N\n",
    "\n",
    "def count_even(n)\n",
    "    for i in range(n):\n",
    "    if i%2 = 0\n",
    "        count += n\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to count the sum of odd natural numbers till N\n",
    "\n",
    "def count_odd(n)\n",
    "    for i in (0,n)\n",
    "        if i%2 != 0\n",
    "        count += i\n",
    "        return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to count the sum of squares of first N natural numbers\n",
    "\n",
    "def count_square(n):\n",
    "return n/6*(n+1)*(2n+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_all(n):\n",
    "    count = count(n)\n",
    "    count_even = count_even(n)\n",
    "    count_odd = count_odd(n)\n",
    "    count_squares = count_square(n)\n",
    "    \n",
    "    print(\"Sum of first {} natural numbers: {}\".format(n,count))\n",
    "    print(\"Sum of all even natural numbers till {} is: {}\".format(n,count_even))\n",
    "    print(\"Sum of all odd natural numbers till {} is: {}\".format(n,count_odd))\n",
    "    print(\"Sum of squares of first {} natural numbers: {}\".format(n,count_squares))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_all(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some libraries needed for the next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "import scipy.ndimage\n",
    "from scipy import misc\n",
    "from glob import glob\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import skimage\n",
    "import imageio\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Image Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need access to data. \n",
    "- You can use this link to add the data to your drive: https://drive.google.com/drive/folders/1pHNxZVrlcKh5usWoNC_V7gR2WdeDutjv\n",
    "\n",
    "- Then go inside the folder **CS_for_MedStudents_data** and you will see the folder **HAM10000**.\n",
    "- Right click on the **HAM10000** folder and click on the **Add to my Drive** option.\n",
    "\n",
    "Now you can run the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/content/drive/My Drive/HAM10000\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the data\n",
    "\n",
    "The HAM10000 (\"Human Against Machine with 10000 training images\") dataset which contains 10,015 dermatoscopic images was made publically available by the Harvard database on June 2018 in the hopes to provide training data for automating the process of skin cancer lesion classifications. The motivation behind this act was to provide the public with an abundance and variability of data source for machine learning training purposes such that the results may be compared with that of human experts. If successful, the appplications would bring cost and time saving regimes to hospitals and medical professions alike.\n",
    "\n",
    "Apart from the 10,015 images, a metadata file with demographic information of each lesion is provided as well. More than 50% of lesions are confirmed through histopathology (histo), the ground truth for the rest of the cases is either follow-up examination (follow_up), expert consensus (consensus), or confirmation by in-vivo confocal microscopy (confocal)\n",
    "\n",
    "You can download the dataset here: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DBW86T\n",
    "\n",
    "The 7 classes of skin cancer lesions included in this dataset are:\n",
    "\n",
    "- Melanocytic nevi\n",
    "- Melanoma\n",
    "- Benign keratosis-like lesions\n",
    "- Basal cell carcinoma\n",
    "- Actinic keratoses\n",
    "- Vascular lesions\n",
    "- Dermatofibroma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyze the metadata of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing metadata and checking for its shape\n",
    "metadata = pd.read_csv(data_dir + '/HAM10000_metadata.csv')\n",
    "print(metadata.shape)\n",
    "\n",
    "# label encoding the seven classes for skin cancers\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(metadata['dx'])\n",
    "print(\"Classes:\", list(le.classes_))\n",
    " \n",
    "metadata['label'] = le.transform(metadata[\"dx\"]) \n",
    "metadata.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a sense of what the distribution of each column looks like\n",
    "\n",
    "font = {'weight' : 'bold',\n",
    "        'size'   : 22}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "fig = plt.figure(figsize=(30,25))\n",
    "\n",
    "ax1 = fig.add_subplot(221)\n",
    "metadata['dx'].value_counts().plot(kind='bar', ax=ax1)\n",
    "ax1.set_ylabel('Count', size=50)\n",
    "ax1.set_title('Cell Type', size = 50)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of images per class is imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing the images\n",
    "\n",
    "label = [ 'akiec', 'bcc','bkl','df','mel', 'nv',  'vasc']\n",
    "label_images = []\n",
    "classes = [ 'actinic keratoses', 'basal cell carcinoma', 'benign keratosis-like lesions', \n",
    "           'dermatofibroma','melanoma', 'melanocytic nevi', 'vascular lesions']\n",
    "\n",
    "fig = plt.figure(figsize=(30, 30))\n",
    "num_images = 5\n",
    "\n",
    "for i in label:\n",
    "    sample = metadata[metadata['dx'] == i]['image_id'][:num_images]\n",
    "    label_images.extend(sample)\n",
    "    \n",
    "for position,ID in enumerate(label_images):\n",
    "    labl = metadata[metadata['image_id'] == ID]['dx']\n",
    "    im_sample = data_dir + \"/\" + labl.values[0] + f'/{ID}.jpg'\n",
    "    im_sample = imageio.imread(im_sample)\n",
    "\n",
    "    plt.subplot(7,num_images,position+1)\n",
    "    plt.imshow(im_sample)\n",
    "    plt.axis('off')\n",
    "\n",
    "    if position%5 == 0:\n",
    "        title = int(position/num_images)\n",
    "        plt.title(classes[title], loc='left', size=30, weight=\"bold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data is an important aspect of training a neural network. An efficient dataloader provides faster iterations over the data and results in faster training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the torchvision.datasets.ImageFolder dataset class. The is already preprocessed into separate folders based on their labels.\n",
    "\n",
    "You can check here : https://pytorch.org/docs/stable/torchvision/datasets.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using the dataset object from above try to count the number of images per class. Look if it matches the histogram data from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count occurence per class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have more than 10000 images in our dataset. So, it is not advisable to load 10000 images at once. We need to load small batches of data at a time.\n",
    "\n",
    "That's where a pytorch dataloader is useful: https://pytorch.org/docs/stable/data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the data loader\n",
    "\n",
    "batch_size = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see some loaded images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to show an image\n",
    "fig = plt.figure(figsize=(30, 30))\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # denormalize change this\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(data_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s, ' % classes[labels[j]] for j in range(len(labels))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation\n",
    "\n",
    "It is a common fact that medical data is scarce. But to learn a very good model, the network needs a lot of data. So to tackle the problem we perform data augmentation.\n",
    "\n",
    "We also perform data augmentation:\n",
    "- Flipping the image horizontally\n",
    "- Rotating image.\n",
    "- Normalizing the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmenting the images by roating by 60 degrees\n",
    "augmentation = transforms.Compose([transforms.RandomRotation(degrees=60)])\n",
    "\n",
    "# apply this to the Imagefolder dataset class\n",
    "\n",
    "# Load the data again\n",
    "\n",
    "# visualize now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hausaufgabe\n",
    "\n",
    "1. Count the appearance of each class using the data_loader object.\n",
    "\n",
    "2. Play around with augmentation - Flip the image, rotate by 90 degrees, crop the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
