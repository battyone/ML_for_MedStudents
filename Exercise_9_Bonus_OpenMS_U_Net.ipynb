{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "CS4MS_Exercise_9_Bonus_OpenMS_U-Net.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H0mibiJgnmv",
        "colab_type": "text"
      },
      "source": [
        "# CS4MS: U-Net Brain MR Multiple Sklerosis Segmentation (OpenMS Dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqzknCZJgKF4",
        "colab_type": "text"
      },
      "source": [
        "*This notebook is based on this GitHub repository:\n",
        "https://github.com/usuyama/pytorch-unet*\n",
        "\n",
        "*and the Open MS dataset from the Laboratory of Imaging Technologies at the University of Ljubljana:\n",
        "Lesjak, Žiga, et al. “A novel public MR image dataset of multiple sclerosis patients with lesion segmentations based on multi-rater consensus.” Neuroinformatics (2017): 1-13.*\n",
        "\n",
        "https://github.com/muschellij2/open_ms_data<br>\n",
        "http://lit.fe.uni-lj.si/tools.php?lang=eng"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fv0M47h6oZE2",
        "colab_type": "text"
      },
      "source": [
        "Run the code below to download the Open MS dataset from GitHub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-X38uV0eE97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install urlpath, see below\n",
        "!pip install urlpath\n",
        "# import required python modules\n",
        "# pathlib helps with local paths\n",
        "from pathlib import Path\n",
        "# same for urls\n",
        "from urlpath import URL\n",
        "# urllib is a library for downloading things\n",
        "import urllib.request\n",
        "\n",
        "# create data folder in colab environment\n",
        "data_root = Path('data')\n",
        "data_root.mkdir(exist_ok=True)\n",
        "\n",
        "# github repo with the multiple sklerosis data\n",
        "open_ms_url = URL('https://github.com/muschellij2/open_ms_data/raw/master/cross_sectional/MNI/')\n",
        "\n",
        "# names of the nifty files in each directory\n",
        "nifty_file_names = {'input_volume':'T1_N4_noneck_reduced_winsor_regtoFLAIR_brain_N4_regtoMNI.nii.gz','mask':'GOLD_STANDARD_N4_noneck_reduced_winsor_regtoFLAIR_regtoMNI.nii.gz'}\n",
        "overwrite = True\n",
        "\n",
        "# download t1 and segmentation nifty files fro each patient 01-30\n",
        "for pat_id in range(1,31):\n",
        "  patient_folder = f'patient{pat_id:02d}'\n",
        "  dest_local_path = data_root / patient_folder\n",
        "  dest_local_path.mkdir(exist_ok=True)\n",
        "  for ftype, fname in nifty_file_names.items():\n",
        "    src_url = open_ms_url / patient_folder / fname\n",
        "    dest_local_file = dest_local_path / fname\n",
        "    if not dest_local_file.is_file() or overwrite:\n",
        "      dest_local_file = (dest_local_path / ftype).with_suffix('.nii.gz')\n",
        "      print(f'Downloading {src_url.parent.name}/{src_url.name} to {dest_local_file}')\n",
        "      urllib.request.urlretrieve(str(src_url), dest_local_file)\n",
        "\n",
        "print('Successfully downloaded all files!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1dw6lofoven",
        "colab_type": "text"
      },
      "source": [
        "Create a dataloader from the downloaded nifty files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXGEL2T3DmM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get module for loading nifty files (a file format similar to DICOM)\n",
        "!pip install SimpleITK\n",
        "import SimpleITK as sitk\n",
        "import numpy as np\n",
        "\n",
        "# read nifty file from path and convert it to a numpy array using the library we just loaded\n",
        "def load_np_from_nifty(path):\n",
        "    \"\"\"load nifty file from path and convert to numpy array\"\"\"\n",
        "    return sitk.GetArrayFromImage(sitk.ReadImage(str(path)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veU4Kln2FGqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lets load a pair of volumes and find more about them\n",
        "test_input = load_np_from_nifty(data_root / 'patient01/input_volume.nii.gz')\n",
        "test_mask = load_np_from_nifty(data_root / 'patient01/mask.nii.gz')\n",
        "print('shape of input volume: ', test_input.shape)\n",
        "print('shape of mask volume: ', test_mask.shape)\n",
        "print('min and max values of input volume: ',test_input.min(), test_input.max())\n",
        "print('unique values of mask:', np.unique(test_mask))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AytqE0dMGBB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's print the central slices of both\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "def show_img(img):\n",
        "  fig = plt.figure()\n",
        "  plt.imshow(img, cmap='gray')\n",
        "  plt.show()\n",
        "\n",
        "for volume in [test_input, test_mask]:\n",
        "  center_slice_num = (np.array(volume.shape) / 2).astype(int)\n",
        "  show_img(volume[center_slice_num[0],:,:])\n",
        "  show_img(volume[:,center_slice_num[1],:])\n",
        "  show_img(volume[:,:,center_slice_num[2]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_TMSOzwNLb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we select the second dimension for slices to have square input images\n",
        "show_img(test_input[:,center_slice_num[1],:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkCaAak0U7u4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test a split of the volume into slices\n",
        "test_slices = [test_input[:,slice_num,:] for slice_num in range(test_input.shape[1])]\n",
        "print(np.array(test_slices).shape)\n",
        "show_img(test_slices[center_slice_num[1]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFP5MGaTmpVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# next we build a dataset with the volumes\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "INPUT_SIZE = 182\n",
        "NUM_CLASSES = 2\n",
        "NUM_CHANNELS = 1\n",
        "\n",
        "class OpenMSDataset(Dataset):\n",
        "    def __init__(self, patient_selection=np.arange(1,31), data_root=Path('data'), transform=None, target_transform=None):\n",
        "        # load volumes from selected patients from disk\n",
        "        input_volumes = [load_np_from_nifty(data_root / f'patient{pat_id:02d}/input_volume.nii.gz') for pat_id in patient_selection]\n",
        "        # preprocess each volume (normalize and split into slices)\n",
        "        input_volumes = [self._prepcocess_volume(volume) for volume in input_volumes]\n",
        "        # make one big list of slices instead of seperate volumes\n",
        "        self.input_slices = np.concatenate(input_volumes)\n",
        "        # load masks\n",
        "        self.target_masks = [load_np_from_nifty(data_root / f'patient{pat_id:02d}/mask.nii.gz') for pat_id in patient_selection] \n",
        "        # split masks into slices and bring them in one big list just like the input slices\n",
        "        self.target_masks = np.concatenate([self._split_volume(volume) for volume in self.target_masks])\n",
        "        self.target_masks = [mask_slice for mask_slice in self.target_masks]\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "    \n",
        "    def _prepcocess_volume(self, volume):\n",
        "      volume = self._normalize_volume(volume)\n",
        "      volume = self._split_volume(volume)\n",
        "      return volume\n",
        "\n",
        "    def _normalize_volume(self, volume):\n",
        "      return (volume - np.min(volume)) / (np.max(volume) - np.min(volume))\n",
        "\n",
        "    def _split_volume(self, volume):\n",
        "      return np.array([volume[:,slice_num,:].reshape(NUM_CHANNELS,INPUT_SIZE,INPUT_SIZE) for slice_num in range(volume.shape[1])])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_slices)\n",
        "    \n",
        "    def __getitem__(self, idx):        \n",
        "        image = torch.from_numpy(self.input_slices[idx])\n",
        "        mask = torch.from_numpy(self.target_masks[idx]).float()\n",
        "        # one hot encoding the mask to have separate tensor for background and mask\n",
        "        background = (mask == 0).float()\n",
        "        lesion = (mask == 1).float()\n",
        "        mask = torch.cat((background,lesion),dim=0)\n",
        "\n",
        "        if self.transform:\n",
        "          image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "          mask = self.target_transform(mask)\n",
        "        return [image, mask]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fINDFaeOO9eq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create dataset with all images for testing\n",
        "all_dataset = OpenMSDataset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdgkYa42b9H1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get a random slice wit mask\n",
        "test_input_slice, test_mask_slice = all_dataset[int(np.random.rand()*len(all_dataset))]\n",
        "\n",
        "print(test_input_slice.shape, test_mask_slice.shape)\n",
        "\n",
        "# print input and corresponding mask\n",
        "show_img(test_input_slice.reshape(INPUT_SIZE,INPUT_SIZE))\n",
        "show_img(test_mask_slice[1].reshape(INPUT_SIZE,INPUT_SIZE))\n",
        "\n",
        "# run this cell multiple times seet different image pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8-0ZSFIYy5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "train_set = OpenMSDataset(patient_selection=np.arange(1,21))\n",
        "val_set = OpenMSDataset(patient_selection=np.arange(21,26))\n",
        "\n",
        "image_datasets = {\n",
        "    'train': train_set, 'val': val_set\n",
        "}\n",
        "\n",
        "batch_size = 25\n",
        "\n",
        "dataloaders = {\n",
        "    'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
        "    'val': DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
        "}\n",
        "\n",
        "dataset_sizes = {\n",
        "    x: len(image_datasets[x]) for x in image_datasets.keys()\n",
        "}\n",
        "\n",
        "dataset_sizes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABLXFIcqYy5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.utils\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, masks = next(iter(dataloaders['train']))\n",
        "\n",
        "print(inputs.shape, masks.shape)\n",
        "for x in [inputs.numpy(), masks.numpy()]:\n",
        "    print(x.min(), x.max(), x.mean(), x.std())\n",
        "\n",
        "# print input and corresponding mask\n",
        "show_img(inputs[3].reshape(INPUT_SIZE,INPUT_SIZE))\n",
        "show_img(masks[3][1].reshape(INPUT_SIZE,INPUT_SIZE))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAE0GtM1q-ta",
        "colab_type": "text"
      },
      "source": [
        "**Define U-Net network architecture**\n",
        "\n",
        "Original idea and paper from  Olaf Ronneberger et al. from the University of Freiburg: https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/\n",
        "\n",
        "![alt text](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png)\n",
        "\n",
        "Nice medium post on this:\n",
        "https://towardsdatascience.com/understanding-semantic-segmentation-with-unet-6be4f42d4b47"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kElThT8Dg-N9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define parts of unet\n",
        "# taken from https://github.com/milesial/Pytorch-UNet\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\"Upscaling then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        # input is CHW\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "        # if you have padding issues, see\n",
        "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
        "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BsBgV32rKXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define U-Net\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        self.down4 = Down(512, 512)\n",
        "        self.up1 = Up(1024, 256, bilinear)\n",
        "        self.up2 = Up(512, 128, bilinear)\n",
        "        self.up3 = Up(256, 64, bilinear)\n",
        "        self.up4 = Up(128, 64, bilinear)\n",
        "        self.outc = OutConv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwFPRmirYy5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchsummary import summary\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = UNet(n_channels=NUM_CHANNELS, n_classes=NUM_CLASSES, bilinear=True)\n",
        "model = model.to(device)\n",
        "\n",
        "summary(model, input_size=(NUM_CHANNELS, INPUT_SIZE,INPUT_SIZE))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NyWj_eqeXAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define DICE loss\n",
        "import torch\n",
        "from torch.autograd import Function\n",
        "\n",
        "class DiceCoeff(Function):\n",
        "    \"\"\"Dice coeff for individual examples\"\"\"\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        self.save_for_backward(input, target)\n",
        "        eps = 0.0001\n",
        "        self.inter = torch.dot(input.view(-1), target.view(-1))\n",
        "        self.union = torch.sum(input) + torch.sum(target) + eps\n",
        "\n",
        "        t = (2 * self.inter.float() + eps) / self.union.float()\n",
        "        return t\n",
        "\n",
        "    # This function has only a single output, so it gets only one gradient\n",
        "    def backward(self, grad_output):\n",
        "\n",
        "        input, target = self.saved_variables\n",
        "        grad_input = grad_target = None\n",
        "\n",
        "        if self.needs_input_grad[0]:\n",
        "            grad_input = grad_output * 2 * (target * self.union - self.inter) \\\n",
        "                         / (self.union * self.union)\n",
        "        if self.needs_input_grad[1]:\n",
        "            grad_target = None\n",
        "\n",
        "        return grad_input, grad_target\n",
        "\n",
        "\n",
        "def dice_coeff(input, target):\n",
        "    \"\"\"Dice coeff for batches\"\"\"\n",
        "    if input.is_cuda:\n",
        "        s = torch.FloatTensor(1).cuda().zero_()\n",
        "    else:\n",
        "        s = torch.FloatTensor(1).zero_()\n",
        "\n",
        "    for i, c in enumerate(zip(input, target)):\n",
        "        s = s + DiceCoeff().forward(c[0], c[1])\n",
        "\n",
        "    return s / (i + 1)\n",
        "\n",
        "\n",
        "def dice_loss(pred, target, smooth = 1.):\n",
        "    pred = pred.contiguous()\n",
        "    target = target.contiguous()    \n",
        "\n",
        "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
        "    \n",
        "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
        "    \n",
        "    return loss.mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znYpuLCgYy5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def calc_loss(pred, target, metrics, bce_weight=0.5):\n",
        "    bce = F.binary_cross_entropy_with_logits(pred, target)\n",
        "        \n",
        "    pred = F.sigmoid(pred)\n",
        "    dice = dice_loss(pred, target)\n",
        "    \n",
        "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
        "    \n",
        "    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n",
        "    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n",
        "    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n",
        "    \n",
        "    return loss\n",
        "\n",
        "def print_metrics(metrics, epoch_samples, phase):    \n",
        "    outputs = []\n",
        "    for k in metrics.keys():\n",
        "        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
        "        \n",
        "    print(\"{}: {}\".format(phase, \", \".join(outputs)))    \n",
        "\n",
        "def train_model(model, optimizer, scheduler, num_epochs=25):\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = 1e10\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "        \n",
        "        since = time.time()\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    print(\"LR\", param_group['lr'])\n",
        "                    \n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            metrics = defaultdict(float)\n",
        "            epoch_samples = 0\n",
        "            \n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)             \n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = calc_loss(outputs, labels, metrics)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                epoch_samples += inputs.size(0)\n",
        "\n",
        "            print_metrics(metrics, epoch_samples, phase)\n",
        "            epoch_loss = metrics['loss'] / epoch_samples\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_loss < best_loss:\n",
        "                print(\"saving best model\")\n",
        "                best_loss = epoch_loss\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val loss: {:4f}'.format(best_loss))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DnJ4-qa7QxH",
        "colab_type": "text"
      },
      "source": [
        "DICE score is the most common metric for segmentation tasks\n",
        "\n",
        "![alt text](https://miro.medium.com/max/486/1*yUd5ckecHjWZf6hGrdlwzA.png)\n",
        "\n",
        "more info here:\n",
        "\n",
        "\n",
        "*   https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient\n",
        "*   https://towardsdatascience.com/metrics-to-evaluate-your-semantic-segmentation-model-6bcb99639aa2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "T4-pmL0CYy5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "import copy\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "model = UNet(n_channels=NUM_CHANNELS, n_classes=NUM_CLASSES, bilinear=True).to(device)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=25, gamma=0.1)\n",
        "\n",
        "model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2WZDlY1Yy5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prediction\n",
        "\n",
        "import math\n",
        "\n",
        "model.eval()   # Set model to evaluate mode\n",
        "\n",
        "test_dataset = OpenMSDataset(patient_selection=np.arange(26,31))\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True, num_workers=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN8tfQ385uMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs, labels = next(iter(test_loader))\n",
        "inputs = inputs.to(device)\n",
        "labels = labels.to(device)\n",
        "\n",
        "pred = model(inputs)\n",
        "inputs = inputs.data.cpu().numpy()\n",
        "labels = labels.data.cpu().numpy()\n",
        "pred = pred.data.cpu().numpy()\n",
        "print(pred.shape)\n",
        "\n",
        "show_img(inputs[0][0])\n",
        "show_img(labels[0][1])\n",
        "show_img(pred[0][1]>0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2N65Q9-nVng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}