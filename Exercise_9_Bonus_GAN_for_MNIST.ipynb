{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "gan-mnist-pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNPG4lh2GhF0",
        "colab_type": "text"
      },
      "source": [
        "# **Generative adversarial networks**\n",
        "\n",
        "In the following notebook we will look at a simple example of a GAN (Generative adversarial network) to understand the concept of its training. The purpose of a GAN is to create new images that appear to be taken samples from a given distribution, in this case handwritten digits (the MNIST dataset)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx4s75mNOJrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "The implementation follows the implementation of simple_GAN of vamsi3\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import imageio\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Importing torch modules\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# For MNIST dataset and visualization\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import make_grid\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1PK4Er1ij_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting the hyper parameters\n",
        "\n",
        "epochs = 200\n",
        "batch_size = 64\n",
        "learning_rate = 0.0002\n",
        "b1 = 0.5  # beta values for optimizer\n",
        "b2 = 0.999  # beta values for optimizer\n",
        "latent_dim = 100\n",
        "img_size = 28\n",
        "channels = 1\n",
        "output_dir = 'output'\n",
        "\n",
        "img_shape = (channels, img_size, img_size)\n",
        "\n",
        "# Check CUDA's presence\n",
        "cuda_is_present = True if torch.cuda.is_available() else False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUwK3zMtHgVZ",
        "colab_type": "text"
      },
      "source": [
        "# **The two opponents**\n",
        "In the next step, we are creating the generator and discriminator class for our training. The purpose of the generator is to create images which seem to be a normal sample from the MNIST dataset. The job of the discriminator is to find the fake samples that the generator is mixing into the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypixkWBNOJrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "\tdef __init__(self):\n",
        "\t\tsuper().__init__()\n",
        "\n",
        "    # This function yields an easy way to define a whole layer containing the\n",
        "    # the linear unit, the batch normalisation and the activation function\n",
        "\t\tdef layer_block(input_size, output_size, normalize=True):\n",
        "\t\t\tlayers = [nn.Linear(input_size, output_size)]\n",
        "\t\t\tif normalize:\n",
        "\t\t\t\tlayers.append(nn.BatchNorm1d(output_size, 0.8))\n",
        "\t\t\tlayers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "\t\t\treturn layers\n",
        "\n",
        "    # The model is upsampling from the latent space to a full fake image. The\n",
        "    # '*' unpacks the list of layers from 'layer_block' into its components so\n",
        "    # they can be put together to form the full model.\n",
        "\n",
        "\t\tself.model = nn.Sequential(\n",
        "\t\t\t*layer_block(latent_dim, 128, normalize=False),\n",
        "\t\t\t*layer_block(128, 256),\n",
        "\t\t\t*layer_block(256, 512),\n",
        "\t\t\t*layer_block(512, 1024),\n",
        "\n",
        "      # np.prod() returns the product of all inputs, so for 'img_shape':\n",
        "      # channel * img_size * img_size. Therefore we now received all the pixels\n",
        "      # we need to reconstruct the image.\n",
        "\n",
        "\t\t\tnn.Linear(1024, int(np.prod(img_shape))),\n",
        "\t\t\tnn.Tanh()  # The values of the image are forced to be between -1 and 1\n",
        "\t\t)\n",
        "\n",
        "\tdef forward(self, z):\n",
        "\t\timg = self.model(z)\n",
        "\t\timg = img.view(img.size(0), *img_shape)  # Vector is reshaped into image\n",
        "    # This is the image the generator is trying to fool the classifier with.\n",
        "\t\treturn img  \n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "\tdef __init__(self):\n",
        "\t\tsuper().__init__()\n",
        "\n",
        "    # This model tries to classify, whether an image is real or not. So the\n",
        "    # classification task is not to define which number is shown, but just if\n",
        "    # the number was drawn by a human or generated by the generator.\n",
        "\n",
        "\t\tself.model = nn.Sequential(\n",
        "\t\t\tnn.Linear(int(np.prod(img_shape)), 512),\n",
        "\t\t\tnn.LeakyReLU(0.2, inplace=True),\n",
        "\t\t\tnn.Linear(512, 256),\n",
        "\t\t\tnn.LeakyReLU(0.2, inplace=True),\n",
        "\t\t\tnn.Linear(256, 1),  # There is only one output (since only two classes)\n",
        "\t\t\tnn.Sigmoid()  # Output is now between 0 and 1 (1 = real, 0 = fake)\n",
        "\t\t)\n",
        "\n",
        "\tdef forward(self, img):\n",
        "\t\timg_flat = img.view(img.size(0), -1)  # The image is reshaped into a vector.\n",
        "\t\tverdict = self.model(img_flat)\n",
        "\t\treturn verdict\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MumZws2Ih3P",
        "colab_type": "text"
      },
      "source": [
        "# **Getting ready**\n",
        "Before we start the training, the finish up the setup and load our dataset MNIST, which is containing several thousand images of handwritten digits. These will be used as the distribution that the generator tries to imitate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_v0mRvKkZGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Utilize CUDA if available\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "adversarial_loss = torch.nn.BCELoss()  # Binary cross entropy loss\n",
        "\n",
        "# The binary cross entropy loss only knows to answers: true and false. It\n",
        "# becomes zero, when the probability for the correct answer is 100% and\n",
        "# infinity when it is 0%.\n",
        "\n",
        "if cuda_is_present:\n",
        "\tgenerator.cuda()\n",
        "\tdiscriminator.cuda()\n",
        "\tadversarial_loss.cuda()\n",
        "\n",
        "# Loading MNIST dataset\n",
        "os.makedirs('data/mnist', exist_ok=True)\n",
        "\n",
        "# Now the dataloader is created, using the predefined dataset.MNIST class from\n",
        "# torchvision to load the MNIST images.\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "\tdatasets.MNIST('/data/mnist', train=True, download=True,\n",
        "\t\ttransform=transforms.Compose([\n",
        "\t\t\t\ttransforms.ToTensor(),\n",
        "\t\t\t\ttransforms.Normalize([0.5], [0.5])\n",
        "\t\t\t])),\n",
        "\tbatch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69QPNgiEJnJk",
        "colab_type": "text"
      },
      "source": [
        "# **The fight begins**\n",
        "During training, the generator starts creating several fake images to fool the discriminator. The discriminator gets to see both real and fake images and learns to distinguish the two groups. So in order to still fool the discriminator, the generator has to become better and better in his job of creating realistic images. Therefore, after training we receive a generator who is now capable of creating realistic samples of handwritten digits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuU0Yaceks_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training the GAN\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda_is_present else torch.FloatTensor\n",
        "\n",
        "# Two optimizers are defined, since the generator and the discriminator are going\n",
        "# to complete with each other during training:\n",
        "optimizer_generator = torch.optim.Adam(generator.parameters(), lr=learning_rate, betas=(b1, b2))\n",
        "optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(b1, b2))\n",
        "\n",
        "losses = []\n",
        "images_for_gif = []\n",
        "for epoch in range(1, epochs+1):\n",
        "  print('Starting epoch number: {}'.format(epoch))\n",
        "  for i, (images, _) in enumerate(data_loader):\n",
        "\n",
        "    real_images = Variable(images.type(Tensor))\n",
        "    real_output = Variable(Tensor(images.size(0), 1).fill_(1.0), requires_grad=False)\n",
        "    fake_output = Variable(Tensor(images.size(0), 1).fill_(0.0), requires_grad=False)\n",
        "\n",
        "    # Training Generator\n",
        "    optimizer_generator.zero_grad()\n",
        "    z = Variable(Tensor(np.random.normal(0, 1, (images.shape[0], latent_dim))))\n",
        "\n",
        "    # The generator creates a batch of fake images:\n",
        "    generated_images = generator(z)\n",
        "\n",
        "    # The discriminator now evaluates the images. The more of them he believes\n",
        "    # to be real, the smaller becomes the generator_loss, since he fools the\n",
        "    # discriminator nicely:\n",
        "    generator_loss = adversarial_loss(discriminator(generated_images), real_output)\n",
        "    generator_loss.backward()\n",
        "    optimizer_generator.step()\n",
        "\n",
        "    # Training Discriminator\n",
        "    optimizer_discriminator.zero_grad()\n",
        "\n",
        "    # The discriminator receives the fake and real images and has to determine\n",
        "    # what is real and what is fake. He receives a small loss, if both the\n",
        "    # real images are determined as real and the fake images are determined as\n",
        "    # fake:\n",
        "    discriminator_loss_real = adversarial_loss(discriminator(real_images), real_output)\n",
        "    discriminator_loss_fake = adversarial_loss(discriminator(generated_images.detach()), fake_output)\n",
        "    discriminator_loss = (discriminator_loss_real + discriminator_loss_fake) / 2\n",
        "    discriminator_loss.backward()\n",
        "    optimizer_discriminator.step()\n",
        "\n",
        "    # print(\"[Epoch {}/{}] [Batch {}/{}] ---> \".format(epoch, epochs, i, len(data_loader)),\n",
        "    #     \"[D Loss: {}] [G Loss: {}]\".format(np.round(discriminator_loss.item(), 4),\n",
        "    #                       np.round(generator_loss.item(), 4)))\n",
        "\n",
        "  # Here, some generated fake images for every epoch are visualised:\n",
        "  losses.append((generator_loss.item(), discriminator_loss.item()))\n",
        "  grid_img = make_grid(generated_images.data[:25].cpu(), nrow=5)\n",
        "  plt.imshow(grid_img.permute(1, 2, 0))\n",
        "  plt.show()\n",
        "\n",
        "# Visualizing the losses at every epoch\n",
        "losses = np.array(losses)\n",
        "plt.plot(losses.T[0], label='Generator')\n",
        "plt.plot(losses.T[1], label='Discriminator')\n",
        "plt.title(\"Training Losses\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}